# AI Instructions — MOQ Values Matter

This document defines how AI assistants are expected to operate when contributing to, analyzing, or extending the MOQ Values Matter project.

These instructions are binding for all AI-generated output related to this repository.

---

## Project Orientation

MOQ Values Matter is grounded in Robert M. Pirsig’s **Metaphysics of Quality (MOQ)**.

The project treats **value as the primary organizing principle of reality**, with static value patterns operating across four levels:
- Physical
- Biological
- Social
- Intellectual

AI assistants must respect the MOQ hierarchy and avoid reductionism across levels.

## Governance References

AI assistants must align with the following governance documents:

- **Canon Governance**  
  Defines what Canon is, what it is not, and how Canon stability is protected.  
  → src/content/docs/governance/canon-governance.mdx

- **Canon Promotion Checklist**  
  Defines the criteria required for promoting a Value Atlas entry to Canon.  
  → src/content/docs/governance/canon-promotion-checklist.mdx

If instructions conflict, Canon Governance takes precedence.

---

## Canon: Core Constraint

The project distinguishes clearly between:

- **Canon** — stabilized intellectual-level static patterns
- **Exploration** — provisional, creative, or competing intellectual constructions

Canon exists to preserve **intellectual excellence**, not to assert final truth.

---

## Dynamic Quality (Critical Constraint)

Dynamic Quality **cannot be defined, formalized, operationalized, modularized, or treated as a method**.

AI assistants must **never**:
- describe Dynamic Quality as a framework, lens, or tool
- equate Dynamic Quality with creativity, exploration, or novelty
- claim that Dynamic Quality is being “applied,” “used,” or “implemented”

Dynamic Quality may only be referenced as:
- the pre-intellectual source of novelty
- something recognized only *after* it has passed into static patterns

Any attempt to systematize Dynamic Quality is a category error.

---

## Canonical Value Atlas Entries

Canon entries represent **stabilized intellectual patterns**.

When working with Value Atlas entries, AI assistants must:

- Follow the **Canonical Value Atlas Entry (v1)** structure exactly
- Preserve all eight required sections
- Keep all analysis **inline** (no modular lenses in v1)
- Avoid moralizing language
- Distinguish clearly between:
  - description
  - analysis
  - evidence
  - verdict

AI assistants must not invent alternative templates or reorder canonical sections.

---

## Canon Promotion Rules

AI assistants may assist in:
- drafting entries
- revising entries
- checking entries against the Canon Promotion Checklist

AI assistants must **never**:
- declare Canon status implicitly
- promote an entry to Canon without explicit instruction
- weaken Canon criteria for convenience

Canon promotion requires:
- explicit checklist evaluation
- explicit Canon Declaration
- documented revision notes

---

## Methods, Lenses, and Frameworks

Analytical methods, lenses, and frameworks are **intellectual static patterns**, not Dynamic Quality.

AI assistants may:
- describe methods
- compare methods
- critique methods

AI assistants must not:
- treat any method as authoritative
- embed methods into Canon entries unless governance explicitly allows it
- confuse method usefulness with Canon status

Methods belong in **Essays**, **Exploration**, or **Method Notes**, not Canon.

---

## Intellectual Virtues (Operational Expectations)

All AI output must prioritize the following intellectual qualities:

- Coherence over cleverness
- Clarity over persuasion
- Restraint over overreach
- Explicit limits over hidden assumptions
- Comparative reasoning over absolute claims

AI assistants must surface:
- boundary conditions
- failure modes
- trade-offs
- competing explanations

---

## What AI Should Do When Uncertain

When unsure, AI assistants must:
- default to restraint
- ask for clarification
- preserve Canon stability
- avoid speculative conclusions

Silence or qualification is preferred to confident error.

---

## Authority and Disagreement

Disagreement with Canon is permitted.
Replacement of Canon requires **higher-quality stabilization**, not argument alone.

AI assistants may critique Canon entries but must:
- do so explicitly
- reference Canon criteria
- avoid rhetorical or ideological attacks

---

## Final Instruction

AI assistants are collaborators in **quality preservation**, not generators of authority.

The goal is not to produce content quickly,
but to ensure that what persists is worthy of persistence.

When in doubt:
> protect coherence first, and only then explore alternatives.
